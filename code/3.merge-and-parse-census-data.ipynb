{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07a88f4",
   "metadata": {},
   "source": [
    "This script will merge the data downloaded in the steps 2 an 3 in a single file, keeping only the relevant columns. Column names will also be renamed for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c08166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c250f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_census_tracts():\n",
    "    '''\n",
    "    Reads census tract data,\n",
    "    selects the relevant variables\n",
    "    and merges them with the polyogns.\n",
    "    '''\n",
    "    \n",
    "    # Variables of interest with their description:\n",
    "    information = {\n",
    "       'setor_censitario_basico_2010' :  {\n",
    "            'v001': 'total_permanent_households',\n",
    "            'v009': 'permanent_household_nominal_mean_income',\n",
    "        },\n",
    "        'setor_censitario_domicilio_renda_2010': {\n",
    "            'v005': 'households_1/8_minimum_wage',\n",
    "            'v006': 'households_1/4_minimum_wage',\n",
    "            'v007': 'households_1/2_minimum_wage',\n",
    "            'v008': 'households_minimum_wage'\n",
    "        },\n",
    "        'setor_censitario_raca_idade_genero_2010': {\n",
    "             'v001': 'total_residents',\n",
    "             'v002': 'white_residents',\n",
    "             'v003': 'black_residents',\n",
    "             'v004': 'yellow_residents',\n",
    "             'v005': 'pardo_residents',\n",
    "             'v006': 'indigenous_residents'\n",
    "        },\n",
    "        'setor_censitario_alfabetizacao_total_2010' : {\n",
    "            'v001': 'literate_residents',\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Reads all files\n",
    "    dfs = []\n",
    "    for k,v in information.items():\n",
    "        \n",
    "        df = pd.read_csv(f\"../data/brazil/censo/resultados/{k}.csv\", dtype={'id_setor_censitario': str})\n",
    "        \n",
    "        df = df.rename(columns={'id_setor_censitario': 'code_tract'})\n",
    "        \n",
    "        if k == \"setor_censitario_domicilio_renda_2010\":\n",
    "            df['total_private_households'] = df.v005 + df.v006 + df.v007 + df.v008 + df.v009 + df.v010 + df.v011 + df.v012 + df.v013 + df.v014\n",
    "            df['private_households_under_minimum_wage'] = df.v005 + df.v006 + df.v007 + df.v008 + df.v014\n",
    "            df = df.drop(columns=[col for col in df.columns if col not in ['code_tract', 'private_households_under_minimum_wage', 'total_private_households']])\n",
    "\n",
    "        else:\n",
    "            df = df.rename(columns=v)\n",
    "            df = df.drop(columns=[col for col in df.columns if col not in v.values() and col != 'code_tract'])\n",
    "        \n",
    "\n",
    "        dfs.append(df)\n",
    "        \n",
    "    # Reduce merge - https://stackoverflow.com/a/30512931\n",
    "    dfs = reduce(lambda left,right: pd.merge(left,right,on='code_tract'), dfs)    \n",
    "    \n",
    "    # Merge with the polygons\n",
    "    gdf = gpd.read_file(\"../data/brazil/censo/malha/setores.zip/\", dtype={'code_tract': str})\n",
    "    \n",
    "    gdf = gdf.merge(dfs, on='code_tract')\n",
    "    return gdf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b3bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    gdf = read_census_tracts()\n",
    "    gdf.to_feather(\"../data/brazil/censo/combined/combined.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77665d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/menegat/opt/anaconda3/envs/dams/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
